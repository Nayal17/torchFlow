{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dJtpV3xufYN"
   },
   "source": [
    "# Walkthrough notebook\n",
    "\n",
    "This notebook walks through our inference script.\n",
    "\n",
    "### Setting up the environment\n",
    "Create a new virtual environment using `venv` or if already created, move on to the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEkKZIBFueOt"
   },
   "outputs": [],
   "source": [
    "# !python3 -m venv venv\n",
    "# !source venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLFKSz8Rug_0"
   },
   "source": [
    "### Cloning the repo\n",
    "Clone the repo and install the required packages defined in `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ouowDB87uh5b"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/arnavrneo/torchFlow.git\n",
    "%cd torchFlow\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1LLZuTvujAk"
   },
   "source": [
    "Run the following shell script to (skip this if the data is already arranged):\n",
    "- download the `yolo` and `onnx` model checkpoints to the `models` directory;\n",
    "- download the tiled datasets in their respective directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OV3pQTnzuj1U"
   },
   "outputs": [],
   "source": [
    "!./get-dataset.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmKOfChTuYbs"
   },
   "source": [
    "### Inferencing\n",
    "We provide inferencing scripts for both model formats:\n",
    "- YOLOv8 format; and\n",
    "- ONNX format.\n",
    "\n",
    "### Yolov8 Format (`inference-yolo.py`)\n",
    "\n",
    "The script arguments are:\n",
    "- `-m`: path to model checkpoint\n",
    "- `-p`: image path/source directory\n",
    "- `-f`: submission.csv path\n",
    "- `-s`: save path for submission.csv\n",
    "- `-r`: to save result plotted images (saved to `runs` directory)\n",
    "\n",
    "The saved `submission.csv` will contain the predicted results according to the submission format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rcUpY7jEuTce"
   },
   "outputs": [],
   "source": [
    "!python inference-yolo.py -m /content/torchFlow/models/torchFlow-ckpt.pt \\\n",
    "          -p dataset/predict-path \\\n",
    "          -f /content/torchFlow/submission.csv \\\n",
    "          -s /content/ \\\n",
    "          -r False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XIOdtj40uaCb"
   },
   "source": [
    "### ONNX Format (`inference-onnx.py`) [WIP]\n",
    "\n",
    "For inferencing using ONNX model, the script has the following arguments:\n",
    "- `-m`: path to model checkpoint\n",
    "- `-p`: image path\n",
    "\n",
    "The `submission.csv` will contain the predicted results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZGetO88ubf1"
   },
   "outputs": [],
   "source": [
    "!python inference-onnx.py -m /content/torchFlow/models/torchFlow-ckpt.pt \\\n",
    "          -p dataset/predict-path \\\n",
    "          -f /content/torchFlow/submission.csv \\\n",
    "          -s /content/ \\\n",
    "          -r False"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNOfhdLmP9bPvdqu6kaw3I1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
