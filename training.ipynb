{"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMQbNzUzjrx7EDIIDY5vuTP","gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training & Validation notebook\n\nThis notebook walks through our training and validation scripts.\n\n### Setting up the environment\nCreate a new virtual environment using `venv` or if already created, move on to the next part (skip this if running on Google colab).","metadata":{"id":"hElqFYPmt83U"}},{"cell_type":"code","source":"# !python3 -m venv venv\n# !source venv/bin/activate","metadata":{"id":"GzX_zfmQuELz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cloning the repo\nClone the repo and install the required packages defined in `requirements.txt`.","metadata":{"id":"u4C_GdGruFYE"}},{"cell_type":"code","source":"%%capture\n!git clone https://github.com/arnavrneo/torchFlow.git\n%cd torchFlow\n!pip install -r requirements.txt","metadata":{"id":"RthdxopNqp6L","execution":{"iopub.status.busy":"2023-07-04T12:56:23.268614Z","iopub.execute_input":"2023-07-04T12:56:23.268985Z","iopub.status.idle":"2023-07-04T12:57:05.050539Z","shell.execute_reply.started":"2023-07-04T12:56:23.268936Z","shell.execute_reply":"2023-07-04T12:57:05.049266Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Run the following shell script to (skip this if the data is already arranged):\n- download the `yolo` and `onnx` model checkpoints to the `models` directory;\n- download the tiled datasets in their respective directories.","metadata":{"id":"dBizNE2kuHlc"}},{"cell_type":"code","source":"%%capture\n!./get-data.sh","metadata":{"id":"vALjJwosq9dX","execution":{"iopub.status.busy":"2023-07-04T12:57:44.325902Z","iopub.execute_input":"2023-07-04T12:57:44.326660Z","iopub.status.idle":"2023-07-04T12:58:23.474566Z","shell.execute_reply.started":"2023-07-04T12:57:44.326625Z","shell.execute_reply":"2023-07-04T12:58:23.473334Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!python config/config.py # for setting up the dataset directorys","metadata":{"executionInfo":{"elapsed":422,"status":"ok","timestamp":1688453661802,"user":{"displayName":"Arnav Raina","userId":"07680225500290338216"},"user_tz":-330},"id":"js728FG9rib2","execution":{"iopub.status.busy":"2023-07-04T12:58:38.054900Z","iopub.execute_input":"2023-07-04T12:58:38.056232Z","iopub.status.idle":"2023-07-04T12:58:39.106088Z","shell.execute_reply.started":"2023-07-04T12:58:38.056185Z","shell.execute_reply":"2023-07-04T12:58:39.104828Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Training\n\nFor training, we have trained the model by tiling the dataset into the following sizes:\n- 256 x 256\n- 512 x 512\n- 1280 x 1280\n\nand recursively training the model on next tiled dataset and then finally training at 3200 x 2600 size on the original dataset.\n\nThe base model used: `yolov8l.pt`.\n\nFor replicating training process, keep changing:\n- the model sizes acc. to the tile size (keep the params as it is) in the `train-config.yaml` file.\n![epochs-sizes.png](assets/epochs-sizes.png)\n\n\n- and the dataset directory path in the `dataset.yaml`, i.e.\n\n![dataset-yaml.png](assets/dataset-yaml.png)\n\n- and the model checkpoints.\n\nThe arguments:\n- `-m`: model path","metadata":{"id":"KW1v-Rw5rdC9"}},{"cell_type":"code","source":"!python train.py -m yolov8l.pt","metadata":{"id":"w5WdAvFGreEt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Validation\n\nValidation will be done automatically during the training step, but for manual validation, we provide the `val.py` script.\n- We run the validation at `3232` size. The values can be changed in the `val-config.yaml`.\n\nThe arguments:\n- `-m`: model path","metadata":{"id":"usce_1cjsbQe"}},{"cell_type":"code","source":"!python val.py -m /kaggle/working/torchFlow/models/torchFlow-ckpt.pt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41406,"status":"ok","timestamp":1688454101799,"user":{"displayName":"Arnav Raina","userId":"07680225500290338216"},"user_tz":-330},"id":"eb0yDFVisb-8","outputId":"9913c1e3-7567-4a4e-f201-35173ca02310","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}